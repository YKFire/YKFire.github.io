---
title: 深度了解ChatGPT
date: 2023-07-02 22:47:00 +0800
categories: [随笔]
tags: [学习]
pin: true
author: YKFire

toc: true
comments: true

math: false
mermaid: true

typora-root-url: ../../YKFire.github.io

---

 

​	从今年年初，OpenAI发布的ChatGPT已摧古拉朽之势席卷全球，短短两个月注册用户数就超过1亿人，是全世界增长速度最快的应用。你如果不聊两句ChatGPT,都不好意思出门。很多人都说今年是AI元年，其实也是有一定道理的，之前的AI门槛相对较高，很多人没有机会参与其中，而类ChatGPT的出现，把AIGC的门槛几乎降到了零，让普通人也可以参与到AI的浪潮中，一个人人可以AI创业的时代到来了！



## 一、什么是ChatGPT?

ChatGPT从字面上可以分解成两个词Chat+GPT。Chat是聊天的意思，GPT是Generative Pre-trained Transformer的缩写，生成式预训练语言模型，使用Transformer架构来处理自然语言处理（NLP）任务。也就是说GPT能理解自然语言，大家能够用汉语、英语等自然语言跟GPT交流，而且它有大量的训练语料，超大规模的训练参数（上千亿），能自己生成内容，并不是像搜索引擎一样只是简单的检索，就算一个它不知道的东西，它都可以根据已掌握的数据，生成一个答案，虽然有时候可能在胡说八道，从这个角度，确实已经很像人类了。



总结一下就是，他有丰富的知识库，是一个知识渊博的智者，当你向他提问时，他能听懂你的提问，并且可以非常智能的生成答案（注意这里不是检索，所以你会发现每次向GPT提问同样的问题，得到的答案都是不一样的）



PS:关于为什么向GPT提同样的问题得到不同的答案这个问题，这里我简单的说一下，GPT是一个深度神经网络，里面有几百亿甚至上千亿的参数，为了得到更多的发散性，每次可能走的神经网络不会完全相同，最终的结果就不会完全相同，所以你有时候会看到GPT在一本正经的胡说八道，可能也正是因为他的这个特点，让GPT看起来更像一个人吧。



## 二、大模型发展这么久，为什么到GPT3.5才具有了真正的智能？

大家通过上面的阅读知道，GPT（Generative Pre-trained Transformer）生成式预训练语言模型。也就是这个语言模型是基于Transformer的，Transformer是一种基于注意力机制的神经网络模型，最早由谷歌公司提出，其最初目的是用于自然语言处理任务，如机器翻译、文本摘要、语音识别等。相比于传统的循环神经网络模型，如LSTM和GRU，Transformer模型具有更好的并行化能力和更短的训练时间，在处理长序列任务方面表现出色，因此在自然语言处理领域得到了广泛应用。



其实GPT不是OpenAI公司的原创，而是由谷歌公司发明。是不是跟当年操作系统的图形用户界面其实是施乐公司最新发明的，却被乔布斯窃取到并应用到苹果的系统上一样。包括后来的iphone手机，大家也可以搜一下，其实所有的设计都是借鉴了其他公司的产品，但是乔布斯把他们组合并创新成了一件最伟大的艺术品，从而开启了一个全新的移动互联网时代，所以有时候并不一定什么都要原创，站在巨人的肩膀上来微创新，有时候更容易出成果。



上面扯的有点远了，我们回到为什么GPT3.5才算真正的人工智能这个问题上。



2018 年 OpenAI 采用 Transformer Decoder 结构在大规模语料上训练了 GPT1 模型，揭开了NLP模型预训练+微调的新范式。2019 年，OpenAI 提出了 GPT2，GPT2 拥有和 GPT1 一样的模型结构，但得益于更多和更高的数据质量以及新引入的多任务学习方式，语言生成能力得到大幅提升。之后由于 GPT 采用 Decoder 单向结构天然缺陷是无法感知上下文，Google 很快提出了 Encoder 结构的 Bert 模型可以感知上下文，效果上也明显有提升，同年 Google 采用Encoder-Decoder 结构，提出了 T5 模型，从此大规模预训练语言模型朝着三个不同方向发展。



也就是说在GPT3.0之前，谷歌的Bert 模型是远超OpenAI 的GPT模型的。这里补充一个知识点，GPT3.0之前都是开源的，OpenAI由于一些商业等多方面的考虑，从GPT3.5开始，模型都是闭源的。



直到2020 年 OpenAI 提出了 GPT3 将 GPT 模型提升到全新的高度，其训练参数达到了 1750 亿，训练语料超45TB，自此GPT系列模型的数据飞轮便转动起来，超大模型时代开启， NLP 任务走向了预训练+情境学习新路线。由于 GPT3 可以产生通顺的句子，但是准确性等问题一直存在，于是出现了InstructGPT、ChatGPT 等后续优化的工作，通过加入强化学习模式实现了模型可以理解人类指令的含义，会甄别高水准答案，质疑错误问题和拒绝不适当的请求等。



从GPT3.5，GPT突然涌现出了“乌鸦”能力，之前的都可以理解成量变，一种鹦鹉学舌的能力，并没有真正的智能。

可能是大力出奇迹，我感觉跟人脑是一个道理，一个神经元没啥智慧，一百万个、一百亿个可能也没啥智慧，不过增加到一千亿个神经元连接，突然就有智慧了，涌现出了能力。这是一件很玄学的事情，包括现在世界顶级的人工智能专业也无法解释这种现象，我们只能理解成大力出奇迹。



这里拿出一点篇幅来普及一下什么“鹦鹉学舌”的假人工智障，什么是拥有“乌鸦”能力的真人工智能

所谓鹦鹉学舌，就是东施效颦。没有GPT之前，几乎所有的自然语言处理都遵循着这一范式。他没有真的懂你的意思，只是一种模式匹配，比如之前的语音助手，只能识别有限的场景，比如你问他，帮我导航去天安门，他可以给你答案，但如果你让问他火星怎么去，他可能就回答不了你，因为他的数据库里没有这个问题的答案。也就是说，他只能回答在自己的数据库里有对应答案的问题，一旦你的问题超出了他的数据范围，他是没办法给你回复的。无法做到根据现有的数据生成新的数据，但是世界的问题千千万，不可能穷尽所有的可能把所有的问题答案都事先准备好，这也是之前的人工智能大家感觉并不智能的原因，因为他的底层实际上还是在做匹配。我举一个程序员都能理解的例子，比如你要实现一个不同条件得到不同结果的功能，我相信大部分程序员都是这样实现的。

```php
if($sex == '男' && $age < 18){
echo "小男孩";
}else if($sex == '女' && $age < 18){
echo "小女孩";
}else if($sex == '男' && $age >= 18 && $age <= 35){
echo "小伙子";
}else if($sex == '女' && $age >= 18 && $age <= 35){
echo "小姑娘";
}else{
echo "老年人";
}
```

如果新增了条件，还是要新增一堆的if else才能匹配更多的情况。



而乌鸦不一样，小时候我们读过乌鸦喝水的故事，乌鸦是有真正智慧的，他能真的读懂你要表达的意思。这里我们引用华人最厉害的AI学者之一朱松纯教授，在2017年写的一篇思考人工智能和智能本质的文章，通过这篇文章来理解乌鸦是如何感知、认知、推理、学习、执行的。

![img](/assets/blog_res/2023-07-02-gpt.assets/FhLB2lRsmBxmqRzTTyLoepIlPyw3.png)

乌鸦通过观察，自主串通了

1. 汽车能压碎坚果
2. 红绿灯能控制汽车
3. 车能撞死我

这三件事情，从而利用红绿灯和汽车，来帮自己达到“安全打开坚果”这一任务结果。

如果类比成机器学习模型，过往“鹦鹉学舌”范式的解法，是要求所有乌鸦可以共享一个大脑，它们有很清晰的优化目标，即“保住性命的前提下打开坚果”。它们的方式是，随机尝试所有事件的组合，并向着最优解的方向不断演化。



但现实世界的乌鸦无法共享大脑，也不能去冒着死亡风险去尝试所有可能。乌鸦只有一次机会，把观测到的两个现象，产生了一个新的可能性，并应用在一个全新的场景下。这里最接近的词汇可能是“inference”，是“基于证据和逻辑推演，得到结论”的过程，有的时候，还要加入很多猜测、抽象、泛化。举个例子，这篇文章把朱教授对于乌鸦的比喻，跟ChatGPT最本质的能力联系起来，就是在做inferencing这件事。



但很明显，inferencing不是乌鸦智能的全部。而且在机器学习领域里，inferencing特指使用训练好的深度学习模型来预测新的数据这一件事，会产生误解。其他词汇也有类似问题，所以我们在自己文章里，会直接使用“乌鸦能力”来指代ChatGPT的新能力。在对外交流时，我们没办法每次都把乌鸦能力是什么解释一遍，所以我们会用“理解”能力来进行指代。从“乌鸦”到“理解”，当然是一个信息量损失很大的过度概括。但是好处是可以把ChatGPT的本质能力凸显出来。**过往互联网的两次能力跃进一次来自于搜索，一次来自于推荐，现在ChatGPT带来了“理解”，也非常有结构感。**



本节最后，再给大家看一张图，让大家了解ChatGPT是如何一步步演化到目前的水平的

![img](/assets/blog_res/2023-07-02-gpt.assets/FmcPfKiOsJyiB63ya7Swly-OGZEV.png)

通过上图，大家可以看到：

1. GPT-3.5通过InstructGPT的模式 + 阅读代码，**涌现了“乌鸦”能力**，产生了质变。但是还没找到合适的应用界面，也不符合人类喜好
2. ChatGPT在RLHF的帮助下，找到了GPT-3.5和人类自然语言的合理接口，解锁了模型应用的前景

（以上关于鹦鹉学舌和乌鸦能力的例子引用自"课代表立正的文章"）



这里解释几个专用名词：

**InstructGPT：**

ChatGPT的交互模式，让GPT的能力，更加贴近人类真实交互方式。在in-context learning基础之上，进一步降低了prompting的门槛；一定程度解决了GPT-3生成结果与用户期望不一致的非预期输出，大幅降低了有害的、错误或偏差的输出结果，让GPT更符合人类胃口

**RLHF**

ChatGPT背后的核心技术之一，让模型学习人类的偏好。全称是reinforcement learning from human feedback，通过构建人类反馈数据集，训练一个reward模型，模仿人类偏好对结果打分，是GPT-3后时代LLM越来越像人类对话的核心技术

**ChatGPT**

InstructGPT的亲戚，但一些优化方式也带来了ChatGPT的更泛化和准确能力，再次引爆了AIGC。ChatGPT总体来说和InstructGPT一样是使用RLHF进行训练，但模型是基于GPT3.5，而且数据设置上也不同。ChatGPT是一个输入，模型给出多个输出，然后人给结果排序，让模型可以学习人类的排序策略，即使是一本正经的胡说八道看起来也很合理的样子



## 三、总结

AI时代已来，面对每天海量的信息铺面而来，我想说，不要焦虑、不要担心自己会被替代，最好的方式就是保持一颗平常心，主动的拥抱AI，让AI成为你的个人助理，根据自身的情况，先从能马上提高自己工作生活效率的内容学起，躬身入局，日拱一卒，相信不久的将来，你一定会感谢今天的你的坚持！
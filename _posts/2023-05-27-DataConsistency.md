---
title: 如何解决数据库与缓存数据一致的问题?
date: 2023-05-27 15:18:00 +0800
categories: [技术实践]
tags: [学习]
pin: true
author: YKFire

toc: true
comments: true

math: false
mermaid: true

typora-root-url: ../../YKFire.github.io

---



> 当我们在项目中引入redis缓存后，我们就必须考虑“数据库与缓存的数据一致性”这个问题，本文笔者将去剖析产生这个问题的原因以及给出整理后的解决方法与最佳实践

## 一、常用的解决方法

先给出解决方法：

- 先更新缓存，再更新数据库

- 先更新数据库，再更新缓存
- 先删除缓存，再更新数据库
- 先更新数据库，再删除缓存

在更新的时候，操作缓存和数据库无疑就是以上四种可能之一



## 二、每种情况下会产生的数据不一致问题



### 1.先更新缓存，再更新数据库

![image-20230527155348184](/assets/blog_res/2023-05-27-DataConsistency.assets/image-20230527155348184.png)

**如果我成功更新了缓存，但是在执行更新数据库的那一步，服务器突然宕机了，那么此时，我的缓存中是最新的数据，而数据库中是旧的数据**。

脏数据就因此诞生了，并且如果我缓存的信息（是单独某张表的），而且这张表也在其他表的关联查询中，那么其他表关联查询出来的数据也是脏数据，结果就是直接会产生一系列的问题。



### 2.先更新数据库，在更新缓存

![image-20230527155501849](/assets/blog_res/2023-05-27-DataConsistency.assets/image-20230527155501849.png)

只有等到缓存过期之后，才能访问到正确的信息。那么在缓存没过期的时间段内，所看到的都是脏数据。

从上面两张图中，大家也能看出，无论咋样，**只要执行第二步时失败了，就必然会产生脏数据。**

如果两步都能执行成功？能保证数据一致性吗？ 其实也不能，因为还有**Java常考的并发**。



### 3.不建议更新缓存

并发情况下的思考

第一种情况

![image-20230527155738984](/assets/blog_res/2023-05-27-DataConsistency.assets/image-20230527155738984.png)

第二种情况

![image-20230527155756171](/assets/blog_res/2023-05-27-DataConsistency.assets/image-20230527155756171.png)

在这里可以看到**当执行时序被改变，那么就必然会产生脏数据**。

看到这里，也许学过 Java 锁知识的小伙伴可能会说，咱们可以加锁啊，这样就不会产生这样的问题啦~

在这里确实可以加锁，以保证用户的请求顺序，来达到数据一致性。

**虽然加锁确实可以通过牺牲一些性能来保证一定数据一致性，但我还是不推荐更新缓存的方式。**

原因如下：

1. 首先加入缓存的主要作用是提高系统性能。
2. 其次更新缓存的代价并不低。

- - 复杂场景下：比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。

3. 缓存利用率问题。一个频繁更新的缓存，它是否会被频繁的访问呢？

- - 一个缓存在很短的时间内，更新10次，20次或者更多，但是实际访问次数只有1、2次，这其实也是一种浪费。
  - 如果采用删除缓存就不会这样，删除了缓存，那么就只会等到有人要使用缓存的时候，才会重新查询数据，放入缓存中。这其实也是懒加载的思想，等到要使用了，再加载。

当然业务场景确实有这样的场景，这么使用也未免不可， 一切都要实事求是，而并非空谈。



> 当然，难道先删除缓存，再更新数据库，或者是先更新数据库，再删除缓存就没有问题了吗？

### 4.先删除缓存，再更新数据库

![image-20230527155952968](/assets/blog_res/2023-05-27-DataConsistency.assets/image-20230527155952968.png)

如果只有第一步执行成功，而第二步失败，那么只有缓存中的数据被删除了，但是数据库没有更新，那么在下一次进行查询的时候，查不到缓存，只能重新查询数据库，构建缓存，这样其实也是相对做到了数据一致性。

但如果是处于**读写并发**的情况下，还是会出现数据不一致的情况：

![image-20230527160015700](/assets/blog_res/2023-05-27-DataConsistency.assets/image-20230527160015700.png)

执行完成后，明显可以看出，1号用户所构建的缓存，并不是最新的数据，还是存在问题的~



### 5.先更新数据库，再删除缓存

如果更新数据库成功了，而删除缓存失败了，那么数据库中就会是新数据，而缓存中是旧数据，数据就出现了不一致情况。

![image-20230527160043840](/assets/blog_res/2023-05-27-DataConsistency.assets/image-20230527160043840.png)

和之前一样，**如果两段代码都执行成功，在并发情况下会是什么样呢**？

![image-20230527160105829](/assets/blog_res/2023-05-27-DataConsistency.assets/image-20230527160105829.png)

还是会造成数据的不一致性。

但是此处**达成这个数据不一致性的条件明显会比起其他的方式更为困难** ：

- 时刻1：读请求的时候，缓存正好过期
- 时刻2：读请求在写请求更新数据库之前查询数据库，
- 时刻3：写请求，在更新数据库之后，要在读请求成功写入缓存前，先执行删除缓存操作。

这通常是很难做到的，因为在真正的并发开发中，更新数据库是需要加锁的，不然没一点安全性~

一定程度上来讲，这种方式还是解决了一定程度上的数据不一致性问题的。

```tex
不过在这四种选择中，平常都会优先考虑后两种方式。并且市面上对于这后两种选择，也已经有一些解决方案。
在谈解决方案之前，我们先看看需要解决的问题： 
1.我们要如何保证这两段代码一起执行成功 (即更新数据库 删除缓存这两个操作) 
2.【先删除缓存，再更新数据库】在读写并发时，会产生一个缓存旧数据，而数据库是新数据的问题，这该如何解决呢？
3.加锁可以解决并发情况下出现的不一致问题吗？
```



## 三、数据一致性的补充

简单说，只要使用缓存，**那么必然就会产生缓存和数据库数据不一致的问题。**

在这首先我们要明确一个问题，就是我们的系统是否一定要做到“缓存+数据库”完全一致性？**是否能够接受偶尔的数据不一致性问题？能够接受最长时间的数据不一致性？**

**强一致性**

如果缓存和数据库要达到数据的完全一致，那么就只能读写都加锁，变成串行化执行，系统吞吐量也就大大降低了，一般不是必须达到强一致性，不采用这样的方式。

并且实在过于要求强一致性，会采用限流+降级，直接走MySQL，而不是特意加一层 Redis 来处理。

**弱一致性（最终一致性）**

一般而言，大都数项目中，都只是要求最终一致性，而非强一致性。

最终一致性是能忍受一定时间内的数据不一致性的，只要求最后的数据是一致的即可。

例如缓存一般是设有失效时间的，失效之后数据也会保证一致性，或者是下次修改时，没有并发，也会让数据回到一致性等等。





## 四、数据一致性的解决

> 同时也是更新数据库和缓存时，会造成数据不一致的原因
>
> ①两个操作不是原子  ②多个线程并发访问

### 1.我们要如何保证这两段代码一起执行成功

重试机制 异步 联想到消息队列  采用消息队列进行解决

我们可以**把第二步操作交由消息队列去做，达到一个异步重试的效果。**并且引入消息队列来实现，代价并非想象中的那么大。

当然大家也会说，如果发送消息也失败呢？

有这种可能，但真的不算高，另外消息队列自身是很好的支持高可用的。

1. 首先消息队列在高并发的场景下，可以毋庸置疑的说是一个非常重要的组件啦，所以引入消息队列以及维护消息队列，其实都不能算是额外的负担。
2. 其次消息队列具有持久化，即使项目重启也不会丢失。
3. 最后消息队列自身可以实现可靠性

- - 保证消息成功发送，发送到交换机；
  - 保证消息成功从交换机发送至队列；
  - 消费者端接收到消息，采用手动ACK确认机制，成功消费后才会删除消息，消费失败则重新投递~

![image-20230527160325375](/assets/blog_res/2023-05-27-DataConsistency.assets/image-20230527160325375.png)

> Canal 订阅日志实现

消息队列虽然已经比较简单，但是仍然要手动的进行代码的编写，以及写一个消费者来进行监听，可以说还是比较麻烦，每个地方都还要引入消息队列，发送一个消息~，有没有办法省去这一步呢？有的勒，偷懒的人大有人在勒

现有的解决方案中，**可以使用 alibaba 的开源组件 Canal**，订阅数据库变更日志，当数据库发生变更时，我们可以拿到具体操作的数据，然后再去根据具体的数据，去删除对应的缓存。

![image-20230527160350058](/assets/blog_res/2023-05-27-DataConsistency.assets/image-20230527160350058.png)



### 2.在读写并发时，会产生一个缓存旧数据，而数据库是新数据的问题，这该如何解决呢？

解决这样的问题，其实最好的方式就是在执行完更新数据库的操作后，先休眠一会儿，再进行一次缓存的删除，以确保数据一致性，这也就是市面上给出的主流解决方案--**延时双删**。

![image-20230527160456172](/assets/blog_res/2023-05-27-DataConsistency.assets/image-20230527160456172.png)



### 3.加锁可以解决并发情况下出现的不一致问题吗？

加分布式锁解决！



## 五、最佳实践

对于一些**读多写少、写操作并发竞争不是特别激烈且对一致性要求不是特别高**的情况下，可以采用**事务（高隔离级别） + 先更新数据库再更新缓存的方式**来达到数据一致的诉求。

![image-20230527160713520](/assets/blog_res/2023-05-27-DataConsistency.assets/image-20230527160713520.png)



在对**并发性能要求极高的情况下**，可以考虑**非事物类的其余方式来实现**，如重试机制、或异步补偿机制、或多者结合方式等。

![image-20230527160727936](/assets/blog_res/2023-05-27-DataConsistency.assets/image-20230527160727936.png)

实际使用场景中，对于一致性要求不是特别高、且并发量不是特别大的场景，可以选择**基于数据库事务保证的先更新数据库再更新/删除缓存。**而对于并发要求较高、且数据一致性要求较好的时候，推荐选择**先更新数据库，再删除缓存，并结合删除重试 + 补偿逻辑 + 缓存过期TTL等综合手段**。



